{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from apex import amp\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Root directory for dataset\n",
    "dataroot = \"/media/fico/Data/Celeba/CelebAMask-HQ\"\n",
    "\n",
    "save_directory = \"./Training/Saved_Models/\"\n",
    "\n",
    "img_directory = \"./Training/Saved_Imgs/\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 4\n",
    "\n",
    "# Batch size during training\n",
    "\n",
    "\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 512\n",
    "\n",
    "# Size of feature maps in generator\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.001\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "lambda_gp = 10\n",
    "\n",
    "d_ratio = 1\n",
    "\n",
    "img_batch_size = [(4,16),(8,16),(16,16),(32,16),(64,16),(128,16), (256, 14), (512, 6), (1024, 3)]\n",
    "\n",
    "betas = (0, 0.99)\n",
    "\n",
    "steps = 6000\n",
    "\n",
    "small_penalty_e = .001\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = []\n",
    "for img_size, batch_size in img_batch_size:\n",
    "    dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.CenterCrop(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "    dataload = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=workers, drop_last=True)\n",
    "    data_loaders.append(dataload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hukkelas/progan-pytorch/blob/master/src/models/custom_layers.py\n",
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        div = torch.square(x)\n",
    "        div = torch.mean(div, dim = 1, keepdim = True)\n",
    "        div = div + 10**(-8)\n",
    "        div = torch.square(div)\n",
    "        return x/div\n",
    "\n",
    "class MiniBatchSTD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiniBatchSTD, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        s = x.shape\n",
    "        std = x\n",
    "        std = std - torch.mean(std, dim=0, keepdim= True)\n",
    "        std = torch.mean(torch.square(std), dim=0)\n",
    "        std = torch.sqrt(std + 10**(-8))\n",
    "        std = torch.mean(std)\n",
    "        std = std.to(x.dtype)\n",
    "        std = std.repeat([s[0], 1, s[2], s[3]])\n",
    "        std = torch.cat([x, std], 1)\n",
    "#         print(std.shape)\n",
    "        return std\n",
    "# https://github.com/akanimax/pro_gan_pytorch/blob/master/pro_gan_pytorch/CustomLayers.py\n",
    "class conv2d_e(nn.Module):\n",
    "    def __init__(self, input_c, output_c, kernel, stride, pad):\n",
    "        super(conv2d_e, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.nn.init.normal_(torch.empty(output_c, input_c, kernel, kernel)))\n",
    "        self.bias = torch.nn.Parameter(torch.FloatTensor(output_c).fill_(0))\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        fan_in = (kernel*kernel) * input_c\n",
    "        self.scale = np.sqrt(2) / np.sqrt(fan_in)\n",
    "#         print(self.weight.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.conv2d(input = x, \n",
    "                         weight = self.weight * self.scale, \n",
    "                         stride = self.stride, \n",
    "                         bias = self.bias, \n",
    "                         padding = self.pad)\n",
    "        \n",
    "\n",
    "class linear_e(nn.Module):\n",
    "    def __init__(self, input_c, output_c):\n",
    "        super(linear_e, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.nn.init.normal_(torch.empty(output_c, input_c)))\n",
    "        self.bias = torch.nn.Parameter(torch.FloatTensor(output_c).fill_(0))\n",
    "        fan_in = input_c\n",
    "        self.scale = np.sqrt(2) / np.sqrt(fan_in)\n",
    "#         print(self.weight.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.linear(input = x, \n",
    "                         weight = self.weight * self.scale, \n",
    "                         bias = self.bias)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Gen Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "# Use upsample from latent or use dense layer to upsample?\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "#         self.added = nn.ModuleList([])\n",
    "        self.up_samp = nn.Upsample(scale_factor = 2)\n",
    "#         4\n",
    "        self.start = linear_e(512, 8192)\n",
    "        self.block = nn.Sequential(\n",
    "#             nn.Upsample(scale_factor = 4),\n",
    "            conv2d_e(nz, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end = conv2d_e(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         8\n",
    "        self.block1 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),) \n",
    "        self.end1 = conv2d_e(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         16\n",
    "        self.block2 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end2 = conv2d_e(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         32\n",
    "        self.block3 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end3 = conv2d_e(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         64\n",
    "        self.block4 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(256, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end4 = conv2d_e(256, 3, 1, 1, 0)\n",
    "        \n",
    "#          128\n",
    "        self.block5 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(256, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(128, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end5 = conv2d_e(128, 3, 1, 1, 0)\n",
    "        \n",
    "#          256\n",
    "        self.block6 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(128, 64, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(64, 64, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end6 = conv2d_e(64, 3, 1, 1, 0)\n",
    "\n",
    "#          512\n",
    "        self.block7 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(64, 32, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(32, 32, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end7 = conv2d_e(32, 3, 1, 1, 0)\n",
    "\n",
    "#          1024\n",
    "        self.block8 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(32, 16, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(16, 16, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end8 = conv2d_e(16, 3, 1, 1, 0)\n",
    "\n",
    "#     Get this down to one if statement logic for fade in\n",
    "    def forward(self, input, res, alpha):\n",
    "#         print(input.shape)\n",
    "#         intput1 = se\n",
    "        input1 = self.start(input)\n",
    "        input1 = input1.view(-1,512,4,4)\n",
    "\n",
    "        \n",
    "        if res == 4:\n",
    "            output = self.block(input1)\n",
    "            output = self.end(output)\n",
    "        elif res == 8:\n",
    "            output = self.block(input1)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end(output_old)\n",
    "            output = self.block1(output)\n",
    "            output = self.end1(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 16:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end1(output_old)\n",
    "            output = self.block2(output)\n",
    "            output = self.end2(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 32:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end2(output_old)\n",
    "            output = self.block3(output)\n",
    "            output = self.end3(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 64:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end3(output_old)\n",
    "            output = self.block4(output)\n",
    "            output = self.end4(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 128:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block4(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end4(output_old)\n",
    "            output = self.block5(output)\n",
    "            output = self.end5(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 256:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block4(output)\n",
    "            output = self.block5(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end5(output_old)\n",
    "            output = self.block6(output)\n",
    "            output = self.end6(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 512:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block4(output)\n",
    "            output = self.block5(output)\n",
    "            output = self.block6(output)\n",
    "\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end6(output_old)\n",
    "            output = self.block7(output)\n",
    "            output = self.end7(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "        elif res == 1024:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block4(output)\n",
    "            output = self.block5(output)\n",
    "            output = self.block6(output)\n",
    "            output = self.block7(output)\n",
    "\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end7(output_old)\n",
    "            output = self.block8(output)\n",
    "            output = self.end8(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "#         print(output.shape) \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dis Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Implement batchstdev\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "#         self.added = nn.ModuleList([])\n",
    "        self.down_samp = nn.AvgPool2d(2)\n",
    "    \n",
    "#         4\n",
    "        self.block = nn.Sequential(\n",
    "            MiniBatchSTD(),\n",
    "            conv2d_e(513, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(512, 512, 4, 1, 0),\n",
    "            nn.LeakyReLU(.2),\n",
    "            nn.Flatten(),\n",
    "            linear_e(512, 1))\n",
    "        self.start = conv2d_e(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         8\n",
    "        self.block1 = nn.Sequential(\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start1 = conv2d_e(3, 512, 1, 1, 0)\n",
    "\n",
    "#         16\n",
    "        self.block2 = nn.Sequential(\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start2 = conv2d_e(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         32\n",
    "        self.block3 = nn.Sequential(\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start3 = conv2d_e(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         64\n",
    "        self.block4 = nn.Sequential(\n",
    "            conv2d_e(256, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(256, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start4 = conv2d_e(3, 256, 1, 1, 0)\n",
    "        \n",
    "#         128\n",
    "        self.block5= nn.Sequential(\n",
    "            conv2d_e(128, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(128, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start5 = conv2d_e(3, 128, 1, 1, 0)\n",
    "\n",
    "#         256\n",
    "        self.block6= nn.Sequential(\n",
    "            conv2d_e(64, 64, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(64, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start6 = conv2d_e(3, 64, 1, 1, 0)\n",
    "\n",
    "#         512\n",
    "        self.block7= nn.Sequential(\n",
    "            conv2d_e(32, 32, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(32, 64, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start7 = conv2d_e(3, 32, 1, 1, 0)\n",
    "\n",
    "#         1024\n",
    "        self.block8= nn.Sequential(\n",
    "            conv2d_e(16, 16, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(16, 32, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start8 = conv2d_e(3, 16, 1, 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, input, res, alpha):   \n",
    "        \n",
    "        if res == 4:\n",
    "            output = self.start(input)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 8:\n",
    "            output = self.start1(input)\n",
    "            output = self.block1(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block(output)\n",
    "        \n",
    "        elif res == 16:\n",
    "            output = self.start2(input)\n",
    "            output = self.block2(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start1(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "                \n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 32:\n",
    "            output = self.start3(input)\n",
    "            output = self.block3(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start2(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 64:\n",
    "            output = self.start4(input)\n",
    "            output = self.block4(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start3(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "                \n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 128:\n",
    "            output = self.start5(input)\n",
    "            output = self.block5(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start4(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block4(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "        \n",
    "        elif res == 256:\n",
    "            output = self.start6(input)\n",
    "            output = self.block6(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start5(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block5(output)\n",
    "            output = self.block4(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "        \n",
    "        elif res == 512:\n",
    "            output = self.start7(input)\n",
    "            output = self.block7(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start6(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "                         \n",
    "            output = self.block6(output)\n",
    "            output = self.block5(output)\n",
    "            output = self.block4(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "        \n",
    "        elif res == 1024:\n",
    "            output = self.start8(input)\n",
    "            output = self.block8(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start7(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block7(output)             \n",
    "            output = self.block6(output)\n",
    "            output = self.block5(output)\n",
    "            output = self.block4(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "#         print(output.shape) \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/copy-weights-only-from-a-networks-parameters/5841\n",
    "def update_running_avg(original, copy):\n",
    "    with torch.no_grad(): \n",
    "        params1 = original.named_parameters()\n",
    "        params2 = copy.named_parameters()\n",
    "        dict_params2 = dict(params2)\n",
    "        for name1, param1 in params1:\n",
    "            if name1 in dict_params2:\n",
    "                dict_params2[name1].data.copy_((1 - .999) * dict_params2[name1] + (.999) * param1.data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startup(load_train, mixed_precision):\n",
    "    \n",
    "    netG = Generator(ngpu).to(device)\n",
    "    netD = Discriminator(ngpu).to(device)\n",
    "    netG_copy = deepcopy(netG)\n",
    "    \n",
    "    scalerD = -1\n",
    "    scalerG = -1\n",
    "    \n",
    "    fixed_noise = torch.randn(16, nz, device=device)\n",
    "    \n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=betas)\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=betas)\n",
    "    \n",
    "    training = True\n",
    "    current_data = 0\n",
    "    res = 4\n",
    "    fade_in = False\n",
    "    epoch = 0\n",
    "    \n",
    "    if load_train:\n",
    "    \n",
    "        if not mixed_precision:\n",
    "            pathD = save_directory + \"Regular/\" + \"D/\"\n",
    "            pathG = save_directory + \"Regular/\" + \"G/\"\n",
    "        else:\n",
    "            pathD = save_directory + \"Amp/\" + \"D/\"\n",
    "            pathG = save_directory + \"Amp/\" + \"G/\"\n",
    "        try:  \n",
    "            list_of_files = glob.glob(pathD + '*') # * means all if need specific format then *.csv\n",
    "            latest_file = max(list_of_files)\n",
    "            checkD = torch.load(latest_file)\n",
    "\n",
    "            list_of_files = glob.glob(pathG + '*') # * means all if need specific format then *.csv\n",
    "            latest_file = max(list_of_files)\n",
    "            checkG = torch.load(latest_file)\n",
    "\n",
    "            optimizerD.load_state_dict(checkD['optimizer_state_dict'])\n",
    "            netD.load_state_dict(checkD['model_state_dict'])\n",
    "            optimizerG.load_state_dict(checkG['optimizer_state_dict'])\n",
    "            netG.load_state_dict(checkG['model_state_dict'])\n",
    "            netG_copy.load_state_dict(checkG['copy_model_state_dict'])\n",
    "\n",
    "            if not mixed_precision:\n",
    "                scalerD = -1\n",
    "                scalerG = -1\n",
    "            else:\n",
    "                scalerD = torch.cuda.amp.GradScaler()\n",
    "                scalerG = torch.cuda.amp.GradScaler()\n",
    "                scalerD.load_state_dict(checkD['scaler_state_dict'])\n",
    "                scalerG.load_state_dict(checkG['scaler_state_dict'])\n",
    "\n",
    "            training = checkD['training']\n",
    "            epoch = checkD['next_epoch']\n",
    "            res = checkD['next_res']\n",
    "            current_data = checkD['next_dict']\n",
    "            fade_in = checkD['next_fade']\n",
    "            fixed_noise = checkG['fixednoise']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return [netD, netG, netG_copy, optimizerD, optimizerG, scalerD, scalerG, epoch, res, current_data, fade_in, fixed_noise, training]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(netD, netG, mini_batch, real_imgs, fake_imgs, alpha, res, mixed_precision):\n",
    "    gp_alpha = torch.randn(mini_batch, 1, 1, 1, device = device)\n",
    "    interp = gp_alpha * real_imgs + ((1-gp_alpha) * fake_imgs.detach())\n",
    "    interp.requires_grad = True\n",
    "            \n",
    "    if mixed_precision:\n",
    "        pass\n",
    "    else:\n",
    "        model_interp = netD(interp, alpha = alpha, res = res)\n",
    "\n",
    "\n",
    "    if mixed_precision:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        grads = torch.autograd.grad(outputs=model_interp, inputs=interp,\n",
    "                      grad_outputs=torch.ones(model_interp.size()).to(device),\n",
    "                      create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        grads = torch.square(grads)\n",
    "        grads = torch.sum(grads, dim = [1,2,3])\n",
    "        grads = torch.sqrt(grads)\n",
    "        grads = grads - 1\n",
    "        grads = torch.square(grads)\n",
    "        grad_pen = grads * lambda_gp\n",
    "        return grad_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_penalty(netD, output_real, mixed_precision = False):\n",
    "    if mixed_precision:\n",
    "        pass\n",
    "    else:\n",
    "        penalty = torch.square(output_real)\n",
    "        penalty = penalty * small_penalty_e\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(epoch, res, fade_in, count, alpha, loss_D, loss_G, netG_copy, fixed_noise, mixed_precision):\n",
    "    with open(save_directory + \"log.txt\",\"w\") as f:\n",
    "        print(\"Res:\", res, \"Fade_in:\", fade_in, \"Iter:\",count, \"alpha:\", alpha, file=f)\n",
    "        print(\"W with GP:\", loss_D.item(),  \"Loss G:\", loss_G.item(), file=f)\n",
    "        print(file=f)\n",
    "    print(\"Res:\", res, \"Fade_in:\", fade_in, \"Iter:\",count, \"alpha:\", alpha)\n",
    "    print(\"W with GP:\", loss_D.item(),  \"Loss G:\", loss_G.item())\n",
    "    print()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        guess = netG_copy(fixed_noise, res = res, alpha=alpha)\n",
    "        guess = guess.cpu()\n",
    "        \n",
    "        old_min = torch.min(guess)\n",
    "        old_max = torch.max(guess)\n",
    "        old_range = old_max - old_min\n",
    "        new_range = 1 - 0\n",
    "       \n",
    "        guess = (((guess - old_min)*new_range)/ old_range) + 0\n",
    "        guess = guess.permute(0,2,3,1)\n",
    "\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(16):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(guess[i, :, :])\n",
    "            plt.axis('off')\n",
    "        if mixed_precision:\n",
    "            path = img_directory + \"Training_Imgs_AMP/Res:\" + str(res) + \"_fade_in:\" + str(fade_in) + \"_training_step:\" + str(count) + \".png\"\n",
    "        else:\n",
    "            path = img_directory + \"Training_Imgs/Res:\" + str(res) + \"_fade_in:\" + str(fade_in) + \"_training_step:\" + str(count) + \".png\"\n",
    "        plt.savefig(path, dpi=300)\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(epoch, res, current_data, fade_in, netD, optimizerD, netG, netG_copy, optimizerG, fixed_noise, scalerD, scalerG, training, mixed_precision):\n",
    "    if not mixed_precision:\n",
    "        \n",
    "        pathD = save_directory + \"Regular/\" + \"D/\" + \"next_res:\" + str(res) + \"next_fade:\" + str(fade_in)\n",
    "        pathG = save_directory + \"Regular/\" + \"G/\" + \"next_res:\" + str(res) + \"next_fade:\" + str(fade_in)\n",
    "        torch.save({\n",
    "            'training': training,\n",
    "            'next_epoch': epoch,\n",
    "            'next_res': res,\n",
    "            'next_dict': current_data,\n",
    "            'next_fade': fade_in,\n",
    "            'model_state_dict': netD.state_dict(),\n",
    "            'optimizer_state_dict': optimizerD.state_dict(),\n",
    "            }, pathD)\n",
    "\n",
    "        torch.save({\n",
    "            'model_state_dict': netG.state_dict(),\n",
    "            'optimizer_state_dict': optimizerG.state_dict(),\n",
    "            'fixednoise': fixed_noise,\n",
    "            'copy_model_state_dict': netG_copy.state_dict(),\n",
    "            }, pathG)\n",
    "            \n",
    "    else:\n",
    "    \n",
    "        pathD = save_directory + \"Amp/\" + \"D/\" + str(epoch)\n",
    "        pathG = save_directory + \"Amp/\" + \"G/\" + str(epoch)\n",
    "               \n",
    "        torch.save({\n",
    "            'training': training,\n",
    "            'next_epoch': epoch,\n",
    "            'next_res': res,\n",
    "            'next_dict': current_data,\n",
    "            'next_fade': fade_in,\n",
    "            'model_state_dict': netD.state_dict(),\n",
    "            'optimizer_state_dict': optimizerD.state_dict(),\n",
    "            'scaler_state_dict': scalerD.state_dict(),\n",
    "#                 'amp': amp.state_dict(),\n",
    "            }, pathD)\n",
    "\n",
    "        torch.save({\n",
    "            'model_state_dict': netG.state_dict(),\n",
    "            'optimizer_state_dict': optimizerG.state_dict(),\n",
    "            'fixednoise': fixed_noise,\n",
    "            'scaler_state_dict': scalerG.state_dict()\n",
    "\n",
    "            }, pathG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_directories():\n",
    "    if not os.path.exists(save_directory + \"Regular/D/\"):\n",
    "            os.makedirs(save_directory + \"Regular/D/\")\n",
    "    if not os.path.exists(save_directory + \"Regular/G/\"):\n",
    "            os.makedirs(save_directory + \"Regular/G/\")\n",
    "    if not os.path.exists(save_directory + \"Amp/D/\"):\n",
    "            os.makedirs(save_directory + \"Amp/D/\")\n",
    "    if not os.path.exists(save_directory + \"Amp/G/\"):\n",
    "            os.makedirs(save_directory + \"Amp/G/\")\n",
    "    if not os.path.exists(img_directory + \"Training_Imgs_AMP/\"):\n",
    "            os.makedirs(img_directory + \"Training_Imgs_AMP/\")\n",
    "    if not os.path.exists(img_directory + \"Training_Imgs/\"):\n",
    "            os.makedirs(img_directory + \"Training_Imgs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: 8 Fade_in: True Iter: 16 alpha: 0.0\n",
      "W with GP: 0.23724476993083954 Loss G: 1.2652682065963745\n",
      "\n",
      "Res: 8 Fade_in: True Iter: 5008 alpha: 0.832\n",
      "W with GP: -5.592761039733887 Loss G: 8.764571189880371\n",
      "\n",
      "Epoch time:  22.727141857147217\n",
      "Res: 8 Fade_in: False Iter: 16 alpha: -1\n",
      "W with GP: -8.073394775390625 Loss G: 11.355735778808594\n",
      "\n",
      "Res: 8 Fade_in: False Iter: 5008 alpha: -1\n",
      "W with GP: -6.7167558670043945 Loss G: 9.21228313446045\n",
      "\n",
      "Epoch time:  22.58228588104248\n",
      "Res: 16 Fade_in: True Iter: 16 alpha: 0.0\n",
      "W with GP: -7.301631450653076 Loss G: 9.272726058959961\n",
      "\n",
      "Res: 16 Fade_in: True Iter: 5008 alpha: 0.832\n",
      "W with GP: -19.490299224853516 Loss G: 32.09564208984375\n",
      "\n",
      "Epoch time:  44.33653736114502\n",
      "Res: 16 Fade_in: False Iter: 16 alpha: -1\n",
      "W with GP: -14.31505298614502 Loss G: 30.986555099487305\n",
      "\n",
      "Res: 16 Fade_in: False Iter: 5008 alpha: -1\n",
      "W with GP: -16.555509567260742 Loss G: 31.676475524902344\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4d387cddc314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mcheck_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-4d387cddc314>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(load_train, mixed_precision)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mreal_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def training(load_train = False, mixed_precision = False):\n",
    "    values = startup(load_train, mixed_precision)\n",
    "    netD = values[0]\n",
    "    netG = values[1]\n",
    "    netG_copy = values[2]\n",
    "    optimizerD = values[3]\n",
    "    optimizerG = values[4]\n",
    "    scalerD = values[5]\n",
    "    scalerG = values[6]\n",
    "    epoch = values[7]\n",
    "    res = values[8]\n",
    "    current_data = values[9]\n",
    "    fade_in = values[10]\n",
    "    fixed_noise = values[11]\n",
    "    training = values[12]   \n",
    "    \n",
    "\n",
    "    while(training):\n",
    "\n",
    "        loader = iter(data_loaders[current_data])\n",
    "        count = 0\n",
    "     \n",
    "        start_time = time.time()\n",
    "        \n",
    "        while count < steps:\n",
    "            try:\n",
    "                img = loader.next()\n",
    "            except StopIteration:\n",
    "                loader = iter(data_loaders[current_data])\n",
    "                img = loader.next()\n",
    "            if not fade_in:\n",
    "                alpha = -1\n",
    "               \n",
    "            else:\n",
    "                alpha = count/steps\n",
    "                \n",
    "            mini_batch = len(img[0])\n",
    "    \n",
    "            real_imgs = img[0].to(device)\n",
    "        \n",
    "            noise = torch.randn(mini_batch, nz, device=device)\n",
    "        \n",
    "            netD.zero_grad()\n",
    "            \n",
    "#             Discriminator loss on real images\n",
    "            if mixed_precision:\n",
    "                pass\n",
    "            else:\n",
    "                output_real = netD(real_imgs, alpha=alpha, res=res).squeeze()\n",
    "\n",
    "            \n",
    "#             Discriminator loss on fake images\n",
    "            if mixed_precision:\n",
    "                pass   \n",
    "            else:\n",
    "                fake_imgs = netG(noise, res=res, alpha=alpha)\n",
    "                output_fake = netD(fake_imgs.detach(), alpha=alpha, res=res).squeeze()\n",
    "                \n",
    "                \n",
    "                \n",
    "#             Gradient Penalty\n",
    "            grad_pen = gradient_penalty(netD, netG, mini_batch, real_imgs, fake_imgs, alpha, res, mixed_precision)\n",
    "            \n",
    "\n",
    "#             Extra small penalty\n",
    "            penalty = small_penalty(netD, output_real, mixed_precision)\n",
    "                \n",
    "\n",
    "#             Calculating entire loss and taking step\n",
    "            if mixed_precision:\n",
    "                pass\n",
    "            else:\n",
    "                loss_D = torch.mean(output_fake - output_real + grad_pen + penalty)\n",
    "                loss_D.backward()\n",
    "                optimizerD.step()      \n",
    "                \n",
    "            netG.zero_grad()\n",
    "            \n",
    "#             Generator loss on created batch\n",
    "            if mixed_precision:\n",
    "                pass\n",
    "            else:\n",
    "                output = netD(fake_imgs, alpha=alpha, res=res).squeeze()\n",
    "                loss_G = -torch.mean(output)\n",
    "                loss_G.backward()\n",
    "                optimizerG.step()\n",
    "            \n",
    "            update_running_avg(netG, netG_copy)\n",
    "\n",
    "#             Training Stats\n",
    "                \n",
    "            count += mini_batch\n",
    "            if count %5000 <= mini_batch:\n",
    "                logging(epoch, res, fade_in, count, alpha, loss_D, loss_G, netG_copy, fixed_noise, mixed_precision)\n",
    "\n",
    "        if fade_in == False:\n",
    "            fade_in = True\n",
    "            current_data += 1\n",
    "            if current_data == len(data_loaders):\n",
    "                training= False\n",
    "            res = res * 2\n",
    "        else:\n",
    "            fade_in = False\n",
    "        epoch += 1 \n",
    "       \n",
    "    \n",
    "        save_models(epoch, res, current_data, fade_in, netD, optimizerD, netG, netG_copy, optimizerG, fixed_noise, scalerD, scalerG, training, mixed_precision)\n",
    "\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        print(\"Epoch time: \", epoch_time)\n",
    "\n",
    "check_directories()\n",
    "training(load_train = True, mixed_precision=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
