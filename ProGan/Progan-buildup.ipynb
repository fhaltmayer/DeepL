{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from apex import amp\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Root directory for dataset\n",
    "dataroot = \"/media/fico/Data/Celeba/CelebAMask-HQ\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 4\n",
    "\n",
    "# Batch size during training\n",
    "\n",
    "\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 512\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 4\n",
    "\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "lambda_gp = 10\n",
    "\n",
    "d_ratio = 1\n",
    "\n",
    "img_batch_size = [(4,16),(8,16),(16,16),(32,16),(64,16),(128,16)]\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = []\n",
    "for img_size, batch_size in img_batch_size:\n",
    "    dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.CenterCrop(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "    dataload = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=workers, drop_last=True)\n",
    "    data_loaders.append(dataload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hukkelas/progan-pytorch/blob/master/src/models/custom_layers.py\n",
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        div = torch.square(x)\n",
    "        div = torch.mean(div, dim = 1, keepdim = True)\n",
    "        div = div + 10**(-8)\n",
    "        div = torch.square(div)\n",
    "        return x/div\n",
    "\n",
    "class MiniBatchSTD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiniBatchSTD, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        s = x.shape\n",
    "        std = x\n",
    "        std = std - torch.mean(std, dim=0, keepdim= True)\n",
    "        std = torch.mean(torch.square(std), dim=0)\n",
    "        std = torch.sqrt(std + 10**(-8))\n",
    "        std = torch.mean(std)\n",
    "        std = std.to(x.dtype)\n",
    "        std = std.repeat([s[0], 1, s[2], s[3]])\n",
    "        std = torch.cat([x, std], 1)\n",
    "#         print(std.shape)\n",
    "        return std\n",
    "# https://github.com/akanimax/pro_gan_pytorch/blob/master/pro_gan_pytorch/CustomLayers.py\n",
    "class conv2d_e(nn.Module):\n",
    "    def __init__(self, input_c, output_c, kernel, stride, pad):\n",
    "        super(conv2d_e, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.nn.init.normal_(torch.empty(output_c, input_c, kernel, kernel)))\n",
    "        self.bias = torch.nn.Parameter(torch.FloatTensor(output_c).fill_(0))\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        fan_in = (kernel*kernel) * input_c\n",
    "        self.scale = np.sqrt(2) / np.sqrt(fan_in)\n",
    "#         print(self.weight.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.conv2d(input = x, \n",
    "                         weight = self.weight * self.scale, \n",
    "                         stride = self.stride, \n",
    "                         bias = self.bias, \n",
    "                         padding = self.pad)\n",
    "        \n",
    "\n",
    "class linear_e(nn.Module):\n",
    "    def __init__(self, input_c, output_c):\n",
    "        super(linear_e, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.nn.init.normal_(torch.empty(output_c, input_c)))\n",
    "        self.bias = torch.nn.Parameter(torch.FloatTensor(output_c).fill_(0))\n",
    "        fan_in = input_c\n",
    "        self.scale = np.sqrt(2) / np.sqrt(fan_in)\n",
    "#         print(self.weight.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.linear(input = x, \n",
    "                         weight = self.weight * self.scale, \n",
    "                         bias = self.bias)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "# Use upsample from latent or use dense layer to upsample?\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "#         self.added = nn.ModuleList([])\n",
    "        self.up_samp = nn.Upsample(scale_factor = 2)\n",
    "#         4\n",
    "        self.start = linear_e(512, 8192)\n",
    "        self.block = nn.Sequential(\n",
    "#             nn.Upsample(scale_factor = 4),\n",
    "            conv2d_e(nz, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end = conv2d_e(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         8\n",
    "        self.block1 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),) \n",
    "        self.end1 = conv2d_e(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         16\n",
    "        self.block2 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end2 = conv2d_e(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         32\n",
    "        self.block3 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end3 = conv2d_e(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         64\n",
    "        self.block4 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(256, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end4 = conv2d_e(256, 3, 1, 1, 0)\n",
    "        \n",
    "#          128\n",
    "        self.block5 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(256, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(128, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),)\n",
    "        self.end5 = conv2d_e(128, 3, 1, 1, 0)\n",
    "\n",
    "\n",
    "#     Get this down to one if statement logic for fade in\n",
    "    def forward(self, input, res, alpha):\n",
    "#         print(input.shape)\n",
    "#         intput1 = se\n",
    "        input1 = self.start(input)\n",
    "        input1 = input1.view(-1,512,4,4)\n",
    "\n",
    "        \n",
    "        if res == 4:\n",
    "            output = self.block(input1)\n",
    "            output = self.end(output)\n",
    "        elif res == 8:\n",
    "            output = self.block(input1)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end(output_old)\n",
    "            output = self.block1(output)\n",
    "            output = self.end1(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 16:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end1(output_old)\n",
    "            output = self.block2(output)\n",
    "            output = self.end2(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 32:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end2(output_old)\n",
    "            output = self.block3(output)\n",
    "            output = self.end3(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 64:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end3(output_old)\n",
    "            output = self.block4(output)\n",
    "            output = self.end4(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 128:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block4(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end4(output_old)\n",
    "            output = self.block5(output)\n",
    "            output = self.end5(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "#         print(output.shape) \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dis Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement batchstdev\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "#         self.added = nn.ModuleList([])\n",
    "        self.down_samp = nn.AvgPool2d(2)\n",
    "    \n",
    "#         4\n",
    "        self.block = nn.Sequential(\n",
    "            MiniBatchSTD(),\n",
    "            conv2d_e(513, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(512, 512, 4, 1, 0),\n",
    "            nn.LeakyReLU(.2),\n",
    "            nn.Flatten(),\n",
    "            linear_e(512, 1))\n",
    "        self.start = conv2d_e(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         8\n",
    "        self.block1 = nn.Sequential(\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start1 = conv2d_e(3, 512, 1, 1, 0)\n",
    "\n",
    "#         16\n",
    "        self.block2 = nn.Sequential(\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start2 = conv2d_e(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         32\n",
    "        self.block3 = nn.Sequential(\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start3 = conv2d_e(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         64\n",
    "        self.block4 = nn.Sequential(\n",
    "            conv2d_e(256, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(256, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start4 = conv2d_e(3, 256, 1, 1, 0)\n",
    "        \n",
    "#         128\n",
    "        self.block5= nn.Sequential(\n",
    "            conv2d_e(128, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            conv2d_e(128, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            self.down_samp,)\n",
    "        self.start5 = conv2d_e(3, 128, 1, 1, 0)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, input, res, alpha):   \n",
    "        \n",
    "        if res == 4:\n",
    "            output = self.start(input)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 8:\n",
    "            output = self.start1(input)\n",
    "            output = self.block1(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block(output)\n",
    "        \n",
    "        elif res == 16:\n",
    "            output = self.start2(input)\n",
    "            output = self.block2(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start1(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "                \n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 32:\n",
    "            output = self.start3(input)\n",
    "            output = self.block3(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start2(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 64:\n",
    "            output = self.start4(input)\n",
    "            output = self.block4(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start3(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "                \n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 128:\n",
    "            output = self.start5(input)\n",
    "            output = self.block5(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start4(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block4(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "#         print(output.shape) \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# netG = Generator(ngpu).to(device)\n",
    "# netD = Discriminator(ngpu).to(device)\n",
    "# test = torch.randn(16, nz, device=device)\n",
    "# test1 = torch.randn(16, 3, 128, 128, device=device)\n",
    "\n",
    "# temp = netG(test, res = 128, alpha = .5)\n",
    "# # print(temp.shape)\n",
    "# netD(temp, res = 128, alpha = .5)\n",
    "# torch.save({\n",
    "#             'next_epoch': epoch,\n",
    "#             'next_res': res,\n",
    "#             'next_dict': current_data,\n",
    "#             'next_fade': fade_in,\n",
    "#             'model_state_dict': netD.state_dict(),\n",
    "#             'optimizer_state_dict': optimizerD.state_dict(),\n",
    "#             'scaler_state_dict': scalerD.state_dict()\n",
    "#             }, save_path_D)\n",
    "        \n",
    "#         torch.save({\n",
    "#             'model_state_dict': netG.state_dict(),\n",
    "#             'optimizer_state_dict': optimizerG.state_dict(),\n",
    "#             'fixednoise': fixed_noise,\n",
    "#             'scaler_state_dict': scalerG.state_dict()\n",
    "\n",
    "#             }, save_path_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 32768.0\n",
      "Res: 4 Fade_in: False Iter: 16 alpha: -1\n",
      "W with GP: 27.243316650390625 Loss G: -21.46875\n",
      "\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 1 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Res: 4 Fade_in: False Iter: 5008 alpha: -1\n",
      "W with GP: -0.4594321548938751 Loss G: 1.080078125\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 10000 alpha: -1\n",
      "W with GP: -0.21636445820331573 Loss G: 0.08624267578125\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 10016 alpha: -1\n",
      "W with GP: -0.03187372162938118 Loss G: 0.150634765625\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 15008 alpha: -1\n",
      "W with GP: -0.22097726166248322 Loss G: 0.919921875\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 20000 alpha: -1\n",
      "W with GP: 0.23564276099205017 Loss G: 0.2498779296875\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 20016 alpha: -1\n",
      "W with GP: -0.014194346964359283 Loss G: 0.44091796875\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 25008 alpha: -1\n",
      "W with GP: -0.11775404214859009 Loss G: 1.2294921875\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 30000 alpha: -1\n",
      "W with GP: 0.05693047493696213 Loss G: 0.994140625\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 30016 alpha: -1\n",
      "W with GP: 0.14379870891571045 Loss G: 1.1650390625\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 35008 alpha: -1\n",
      "W with GP: -0.3839406967163086 Loss G: 1.13671875\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 40000 alpha: -1\n",
      "W with GP: 0.6468601226806641 Loss G: 0.7734375\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 40016 alpha: -1\n",
      "W with GP: 0.3346101641654968 Loss G: 0.6650390625\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 45008 alpha: -1\n",
      "W with GP: 0.13485802710056305 Loss G: 0.7841796875\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 50000 alpha: -1\n",
      "W with GP: 0.2759295105934143 Loss G: 2.44140625\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 50016 alpha: -1\n",
      "W with GP: 0.9574943780899048 Loss G: 0.61865234375\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 55008 alpha: -1\n",
      "W with GP: 0.17947500944137573 Loss G: 1.2490234375\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 60000 alpha: -1\n",
      "W with GP: 0.1319882571697235 Loss G: 0.6337890625\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 60016 alpha: -1\n",
      "W with GP: 0.05171845853328705 Loss G: 0.630859375\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 65008 alpha: -1\n",
      "W with GP: 0.19235296547412872 Loss G: 0.8212890625\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 70000 alpha: -1\n",
      "W with GP: -0.1614147424697876 Loss G: 1.751953125\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 70016 alpha: -1\n",
      "W with GP: 0.03384919464588165 Loss G: 1.58203125\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 75008 alpha: -1\n",
      "W with GP: -0.10999709367752075 Loss G: 1.80859375\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 80000 alpha: -1\n",
      "W with GP: -0.10988308489322662 Loss G: 2.0703125\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 80016 alpha: -1\n",
      "W with GP: 0.0149134062230587 Loss G: 2.001953125\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 85008 alpha: -1\n",
      "W with GP: -0.1808527112007141 Loss G: 2.880859375\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 90000 alpha: -1\n",
      "W with GP: -0.04568038135766983 Loss G: 2.8125\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 90016 alpha: -1\n",
      "W with GP: -0.311641663312912 Loss G: 3.25\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 95008 alpha: -1\n",
      "W with GP: 0.007834892719984055 Loss G: 3.23828125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def training(e = -1, mixed_precision = False):\n",
    "    netG = Generator(ngpu).to(device)\n",
    "    netD = Discriminator(ngpu).to(device)\n",
    "    scalerD = -1\n",
    "    ScalderG = -1\n",
    "    fixed_noise = torch.randn(16, nz, device=device)\n",
    "    \n",
    "\n",
    "    # Setup Adam optimizers for both G and D\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=0.001, betas=(0, 0.99))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=0.001, betas=(0, 0.99))\n",
    "    training = True\n",
    "    current_data = 0\n",
    "    res = 4\n",
    "    fade_in = False\n",
    "    epoch = 0\n",
    "    \n",
    "    if mixed_precision:\n",
    "#         scalerD = torch.cuda.amp.GradScaler()\n",
    "#         scalerG = torch.cuda.amp.GradScaler()\n",
    "        [netD, netG], [optimizerD, optimizerG] = amp.initialize(\n",
    "        [netD, netG], [optimizerD, optimizerG], opt_level='O1', num_losses=2)\n",
    "    \n",
    "    if(e > -1):\n",
    "        if mixed_precision:\n",
    "            pathD = \"./Saved_Models_AMP/\" + \"D_Epoch:\" + str(e)\n",
    "            pathG = \"./Saved_Models_AMP/\" + \"G_Epoch:\" + str(e)\n",
    "        else:\n",
    "            pathD = \"./Saved_Models/\" + \"D_Epoch:\" + str(e)\n",
    "            pathG = \"./Saved_Models/\" + \"G_Epoch:\" + str(e)\n",
    "            \n",
    "        checkD = torch.load(pathD)\n",
    "        checkG = torch.load(pathG)\n",
    "        optimizerD.load_state_dict(checkD['optimizer_state_dict'])\n",
    "        netD.load_state_dict(checkD['model_state_dict'])\n",
    "#         scalerD.load_state_dict(checkD['scaler_state_dict'])\n",
    "        \n",
    "        \n",
    "        optimizerG.load_state_dict(checkG['optimizer_state_dict'])\n",
    "        netG.load_state_dict(checkG['model_state_dict'])\n",
    "#         scalerG.load_state_dict(checkG['scaler_state_dict'])\n",
    "        \n",
    "        epoch = checkD['next_epoch']\n",
    "        res = checkD['next_res']\n",
    "        current_data = checkD['next_dict']\n",
    "        fade_in = checkD['next_fade']\n",
    "        fixed_noise = checkG['fixednoise']\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    while(training):\n",
    "        steps = 100000\n",
    "        loader = iter(data_loaders[current_data])\n",
    "        count = 0\n",
    "        \n",
    "    \n",
    "        while count < steps:\n",
    "            try:\n",
    "                img = loader.next()\n",
    "            except StopIteration:\n",
    "                loader = iter(data_loaders[current_data])\n",
    "                img = loader.next()\n",
    "            if not fade_in:\n",
    "                alpha = -1\n",
    "               \n",
    "            else:\n",
    "                alpha = count/steps\n",
    "                \n",
    "            mini_batch = len(img[0])\n",
    "    \n",
    "            real_imgs = img[0].to(device)\n",
    "        \n",
    "            netD.zero_grad()\n",
    "            \n",
    "#             Discriminator loss on real images\n",
    "            if mixed_precision:\n",
    "#                 with torch.cuda.amp.autocast():\n",
    "                output_real = netD(real_imgs, alpha=alpha, res=res).squeeze()\n",
    "#                 output_real = -output_real\n",
    "#                     print(\"output real\", output_real)\n",
    "#                 with amp.scale_loss(output_real, optimizerD, loss_id=0) as errD_real_scaled:\n",
    "#                     errD_real_scaled.backward()\n",
    "            else:\n",
    "                output_real = netD(real_imgs, alpha=alpha, res=res).squeeze()\n",
    "\n",
    "            \n",
    "#             Discriminator loss on fake images\n",
    "           \n",
    "            noise = torch.randn(mini_batch, nz, device=device)\n",
    "            \n",
    "            if mixed_precision:\n",
    "#                 with torch.cuda.amp.autocast():\n",
    "                fake_imgs = netG(noise, res=res, alpha=alpha)\n",
    "#                 with torch.cuda.amp.autocast():\n",
    "                output_fake = netD(fake_imgs.detach(), alpha=alpha, res=res).squeeze()\n",
    "#                 print(\"fake output\", output_fake)\n",
    "#                 with amp.scale_loss(output_fake, optimizerD, loss_id=1) as errD_fake_scaled:\n",
    "#                     errD_fake_scaled.backward()\n",
    "                    \n",
    "            else:\n",
    "                fake_imgs = netG(noise, res=res, alpha=alpha)\n",
    "                output_fake = netD(fake_imgs.detach(), alpha=alpha, res=res).squeeze()\n",
    "                \n",
    "                \n",
    "                \n",
    "#             Gradient Penalty\n",
    "            \n",
    "            gp_alpha = torch.randn(mini_batch, 1, 1, 1, device = device)\n",
    "            interp = gp_alpha * real_imgs + ((1-gp_alpha) * fake_imgs.detach())\n",
    "            interp.requires_grad = True\n",
    "            \n",
    "            if mixed_precision:\n",
    "#                 with torch.cuda.amp.autocast():\n",
    "                model_interp = netD(interp, alpha = alpha, res = res)\n",
    "#                     print(model_interp)\n",
    "            else:\n",
    "                model_interp = netD(interp, alpha = alpha, res = res)\n",
    "            \n",
    "            \n",
    "            if mixed_precision:\n",
    "\n",
    "                grads = torch.autograd.grad(outputs=model_interp, inputs=interp,\n",
    "                          grad_outputs=torch.ones(model_interp.size()).to(device),\n",
    "                          create_graph=True, retain_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "#                 print(grads)\n",
    "#                 inv_scale = 1.0/scalerD.get_scale()\n",
    "#                 grads = grads * inv_scale\n",
    "#                 with torch.cuda.amp.autocast(): \n",
    "                grads = torch.square(grads)\n",
    "                grads = torch.sum(grads, dim = [1,2,3])\n",
    "                grads = torch.sqrt(grads)\n",
    "                grads = grads - 1\n",
    "                grads = torch.square(grads)\n",
    "                grad_pen = grads * lambda_gp\n",
    "#                 with amp.scale_loss(grad_pen, optimizerD, loss_id=2) as gp_scaled:\n",
    "#                     gp_scaled.backward()\n",
    "\n",
    "            else:\n",
    "                \n",
    "                grads = torch.autograd.grad(outputs=model_interp, inputs=interp,\n",
    "                              grad_outputs=torch.ones(model_interp.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "                grads = torch.square(grads)\n",
    "                grads = torch.sum(grads, dim = [1,2,3])\n",
    "                grads = torch.sqrt(grads)\n",
    "                grads = grads - 1\n",
    "                grads = torch.square(grads)\n",
    "                grad_pen = grads * lambda_gp\n",
    "\n",
    "#             Extra small penalty\n",
    "            if mixed_precision:\n",
    "#                 with torch.cuda.amp.autocast():\n",
    "                penalty = torch.square(output_real)\n",
    "                penalty = penalty * .001\n",
    "#                 with amp.scale_loss(penalty, optimizerD, loss_id=2) as p_scaled:\n",
    "#                     p_scaled.backward()\n",
    "            else:\n",
    "                penalty = torch.square(output_real)\n",
    "                penalty = penalty * .001\n",
    "\n",
    "#             Calculating entire loss and taking step\n",
    "            \n",
    "            if mixed_precision:\n",
    "#                 with torch.cuda.amp.autocast():\n",
    "                loss_D = torch.mean(output_fake - output_real + grad_pen + penalty)\n",
    "                with amp.scale_loss(loss_D, optimizerD, loss_id=0) as loss_d_scaled:\n",
    "                    loss_d_scaled.backward()\n",
    "                optimizerD.step()\n",
    "                \n",
    "#                 scalerD.scale(loss_D).backward()\n",
    "\n",
    "\n",
    "#                 scalerD.step(optimizerD)\n",
    "#                 scalerD.update()\n",
    "\n",
    "    \n",
    "            else:\n",
    "                loss_D = torch.mean(output_fake - output_real + grad_pen + penalty)\n",
    "\n",
    "\n",
    "                loss_D.backward()\n",
    "\n",
    "                optimizerD.step()\n",
    "    #             loss_D = loss_fake + loss_real + grad_pen\n",
    "            \n",
    "                \n",
    "                \n",
    "            netG.zero_grad()\n",
    "            \n",
    "#             Generator loss on created batch\n",
    "            if mixed_precision:\n",
    "#                 with torch.cuda.amp.autocast():\n",
    "                output = netD(fake_imgs, alpha=alpha, res=res).squeeze()\n",
    "                loss_G = -torch.mean(output)\n",
    "                with amp.scale_loss(loss_G, optimizerG, loss_id=1) as loss_g_scaled:\n",
    "                    loss_g_scaled.backward()\n",
    "                optimizerG.step()\n",
    "#                 scalerG.scale(loss_G).backward() \n",
    "#                 scalerG.step(optimizerG)\n",
    "#                 scalerG.update()\n",
    "            else:\n",
    "                output = netD(fake_imgs, alpha=alpha, res=res).squeeze()\n",
    "                loss_G = -torch.mean(output)\n",
    "                loss_G.backward()\n",
    "\n",
    "                optimizerG.step()\n",
    "\n",
    "#             Training Stats\n",
    "                \n",
    "            count += mini_batch\n",
    "            if count %5000 <= mini_batch:\n",
    "#                 print(\"inv_scale\", inv_scale)\n",
    "#                 print(\"scale\", scalerD.get_scale())\n",
    "                print(\"Res:\", res, \"Fade_in:\", fade_in, \"Iter:\",count, \"alpha:\", alpha)\n",
    "                print(\"W with GP:\", loss_D.item(),  \"Loss G:\", loss_G.item())\n",
    "#                 print(\"Loss real:\", loss_real.item(), \"Loss Fake:\", loss_fake.item())\n",
    "                print()\n",
    "                with torch.no_grad():\n",
    "                    guess = netG(fixed_noise, res = res, alpha=alpha)\n",
    "                    guess = guess.cpu()\n",
    "                #     guess = next(iter(data_loaders[0]))[0]\n",
    "                #     print(guess[0].shape)\n",
    "                    old_min = torch.min(guess)\n",
    "                    old_max = torch.max(guess)\n",
    "                    old_range = old_max - old_min\n",
    "                    new_range = 1 - 0\n",
    "                    guess = (((guess - old_min)*new_range)/ old_range) + 0\n",
    "                #     guess = guess.float()\n",
    "#                     print(guess.shape, torch.min(guess), torch.max(guess))\n",
    "                #     guess = ((guess *.5 ) + .5)\n",
    "                    guess = guess.permute(0,2,3,1)\n",
    "#                     print(guess.shape, torch.min(guess[0]), torch.max(guess[0]))\n",
    "\n",
    "\n",
    "                    fig = plt.figure(figsize=(4,4))\n",
    "                    for i in range(16):\n",
    "                        plt.subplot(4, 4, i+1)\n",
    "                        plt.imshow(guess[i, :, :])\n",
    "                        plt.axis('off')\n",
    "                    if mixed_precision:\n",
    "                        path = \"./Training_Imgs_AMP/Epoch: \" + str(epoch) + \" training_step: \" + str(count) + \".png\"\n",
    "                    else:\n",
    "                        path = \"./Training_Imgs/Epoch: \" + str(epoch) + \" training_step: \" + str(count) + \".png\"\n",
    "                    plt.savefig(path, dpi=300)\n",
    "                    plt.close('all')\n",
    "        \n",
    "        if mixed_precision:\n",
    "            save_path_D = \"./Saved_Models_AMP/\" + \"D_Epoch:\" + str(epoch)\n",
    "            save_path_G = \"./Saved_Models_AMP/\" + \"G_Epoch:\" + str(epoch)\n",
    "        else:\n",
    "            save_path_D = \"./Saved_Models/\" + \"D_Epoch:\" + str(epoch)\n",
    "            save_path_G = \"./Saved_Models/\" + \"G_Epoch:\" + str(epoch)\n",
    "        \n",
    "        if fade_in == False:\n",
    "            fade_in = True\n",
    "            current_data += 1\n",
    "            if current_data == len(data_loaders):\n",
    "                training= False\n",
    "            res = res * 2\n",
    "        else:\n",
    "            fade_in = False\n",
    "        epoch += 1 \n",
    "            \n",
    "        torch.save({\n",
    "            'next_epoch': epoch,\n",
    "            'next_res': res,\n",
    "            'next_dict': current_data,\n",
    "            'next_fade': fade_in,\n",
    "            'model_state_dict': netD.state_dict(),\n",
    "            'optimizer_state_dict': optimizerD.state_dict(),\n",
    "#             'scaler_state_dict': scalerD.state_dict(),\n",
    "            'amp': amp.state_dict(),\n",
    "            }, save_path_D)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': netG.state_dict(),\n",
    "            'optimizer_state_dict': optimizerG.state_dict(),\n",
    "            'fixednoise': fixed_noise,\n",
    "#             'scaler_state_dict': scalerG.state_dict()\n",
    "\n",
    "            }, save_path_G)\n",
    "        \n",
    "    \n",
    "training( mixed_precision=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "            save_path_D = \"./Saved_Models_AMP/\" + \"D_Epoch:\" + str(epoch)\n",
    "            save_path_G = \"./Saved_Models_AMP/\" + \"G_Epoch:\" + str(epoch)\n",
    "        else:\n",
    "            save_path_D = \"./Saved_Models/\" + \"D_Epoch:\" + str(epoch)\n",
    "            save_path_G = \"./Saved_Models/\" + \"G_Epoch:\" + str(epoch)\n",
    "        \n",
    "        if fade_in == False:\n",
    "            fade_in = True\n",
    "            current_data += 1\n",
    "            if current_data == len(data_loaders):\n",
    "                training= False\n",
    "            res = res * 2\n",
    "        else:\n",
    "            fade_in = False\n",
    "        epoch += 1 \n",
    "            \n",
    "        torch.save({\n",
    "            'next_epoch': epoch,\n",
    "            'next_res': res,\n",
    "            'next_dict': current_data,\n",
    "            'next_fade': fade_in,\n",
    "            'model_state_dict': netD.state_dict(),\n",
    "            'optimizer_state_dict': optimizerD.state_dict(),\n",
    "#             'scaler_state_dict': scalerD.state_dict(),\n",
    "            'amp': amp.state_dict(),\n",
    "            }, save_path_D)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': netG.state_dict(),\n",
    "            'optimizer_state_dict': optimizerG.state_dict(),\n",
    "            'fixednoise': fixed_noise,\n",
    "#             'scaler_state_dict': scalerG.state_dict()\n",
    "\n",
    "            }, save_path_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # OldRange = (OldMax - OldMin)  \n",
    "# # NewRange = (NewMax - NewMin)  \n",
    "# # NewValue = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
    "\n",
    "\n",
    "# fixed_noise = torch.randn(256, nz, device=device)\n",
    "# with torch.no_grad():\n",
    "#     guess = netG(fixed_noise, res = 4, alpha=-1)\n",
    "#     guess = guess.cpu()\n",
    "# #     guess = next(iter(data_loaders[0]))[0]\n",
    "# #     print(guess[0].shape)\n",
    "#     old_min = torch.min(guess)\n",
    "#     old_max = torch.max(guess)\n",
    "#     old_range = old_max - old_min\n",
    "#     new_range = 1 - 0\n",
    "#     guess = (((guess - old_min)*new_range)/ old_range) + 0\n",
    "# #     guess = guess.float()\n",
    "#     print(guess.shape, torch.min(guess), torch.max(guess))\n",
    "# #     guess = ((guess *.5 ) + .5)\n",
    "#     guess = guess.permute(0,2,3,1)\n",
    "#     print(guess.shape, torch.min(guess[0]), torch.max(guess[0]))\n",
    "\n",
    "\n",
    "#     fig = plt.figure(figsize=(4,4))\n",
    "#     for i in range(16):\n",
    "#         plt.subplot(4, 4, i+1)\n",
    "#         plt.imshow(guess[i, :, :])\n",
    "#         plt.axis('off')\n",
    "# #     plt.savefig('end_train.png', dpi=300)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get it working without mixed precision  \n",
    "\n",
    "\n",
    "\n",
    "# #             Discriminator loss on real images\n",
    "#             with torch.cuda.amp.autocast(): \n",
    "#                 output_real = netD(real_imgs, alpha=alpha, res=res).squeeze()\n",
    "#                 loss_real = -torch.mean(output_real)\n",
    "# #                 print(loss_real)\n",
    "# #             print(loss_real) \n",
    "#             scalerD.scale(loss_real).backward()\n",
    "# #             print(loss_real)\n",
    "\n",
    "            \n",
    "#             noise = torch.randn(mini_batch, nz, 1, 1, device=device)\n",
    "            \n",
    "# #             Discriminator loss on fake images\n",
    "#             with torch.cuda.amp.autocast():\n",
    "            \n",
    "#                 fake_imgs = netG(noise, res=res, alpha=alpha)\n",
    "#                 output_fake = netD(fake_imgs.detach(), alpha=alpha, res=res).squeeze()\n",
    "                \n",
    "#                 loss_fake = torch.mean(output_fake)\n",
    "            \n",
    "#             scalerD.scale(loss_fake).backward()\n",
    "            \n",
    "# #             Gradient Penalty\n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 gp_alpha = torch.randn(mini_batch, 1, 1, 1, device = device)\n",
    "#                 gp_alpha = gp_alpha.expand(real_imgs.size(0), real_imgs.size(1), real_imgs.size(2), real_imgs.size(3))\n",
    "#                 interp = gp_alpha * real_imgs + ((1-gp_alpha) * fake_imgs.detach())\n",
    "#                 interp.requires_grad = True\n",
    "#                 model_interp = netD(interp, alpha = alpha, res = res)\n",
    "            \n",
    "#             grads = torch.autograd.grad(outputs=model_interp, inputs=interp,\n",
    "#                               grad_outputs=torch.ones(model_interp.size()).to(device),\n",
    "#                               create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "            \n",
    "# #             Do I need to unscale the gradients for calculating gp for wasserstein?\n",
    "# #             print(scaled_grad_params.shape)\n",
    "# #             inv_scale = 1./scalerD.get_scale()\n",
    "# #             grads = [p * inv_scale for p in scaled_grad_params]\n",
    "# #             print(grads)\n",
    "            \n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 grads = ((grads.norm(2, dim=1) - 1) ** 2).mean()\n",
    "#                 grads += 1e-16\n",
    "#                 grad_pen = grads * lambda_gp\n",
    "# #                 print(grad_pen.item())\n",
    "            \n",
    "#             scalerD.scale(grad_pen).backward()\n",
    "# #             print(grad_pen.item())\n",
    "# #             return\n",
    "#             scalerD.step(optimizerD)\n",
    "#             scalerD.update()\n",
    "#             loss_D = loss_fake + loss_real + grad_pen\n",
    "            \n",
    "                \n",
    "                \n",
    "#             netG.zero_grad()\n",
    "            \n",
    "\n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 output = netD(fake_imgs, alpha=alpha, res=res).squeeze()\n",
    "#                 loss_G = -torch.mean(output)\n",
    "#             scalerG.scale(loss_G).backward()    \n",
    "\n",
    "#             scalerG.step(optimizerG)\n",
    "#             scalerG.update()\n",
    "                \n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
