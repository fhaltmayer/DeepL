{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Root directory for dataset\n",
    "dataroot = \"/media/fico/Data/Celeba/CelebAMask-HQ\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "\n",
    "\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 512\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 4\n",
    "\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "lambda_gp = 10\n",
    "\n",
    "d_ratio = 1\n",
    "\n",
    "img_batch_size = [(4,16),(8,16),(16,16),(32,16),(64,16),(128,16)]\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.8980) tensor(0.8510)\n"
     ]
    }
   ],
   "source": [
    "data_loaders = []\n",
    "for img_size, batch_size in img_batch_size:\n",
    "    dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.CenterCrop(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "    dataload = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=workers, drop_last=True)\n",
    "    data_loaders.append(dataload)\n",
    "\n",
    "x = next(iter(data_loaders[0]))\n",
    "print(torch.min(x[0]), torch.max(x[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "# Use upsample from latent or use dense layer to upsample?\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "#         self.added = nn.ModuleList([])\n",
    "        self.up_samp = nn.Upsample(scale_factor = 2)\n",
    "#         4\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Upsample(scale_factor = 4),\n",
    "            nn.Conv2d(nz, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),)\n",
    "        self.end = nn.Conv2d(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         8\n",
    "        self.block1 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),)\n",
    "        self.end1 = nn.Conv2d(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         16\n",
    "        self.block2 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),)\n",
    "        self.end2 = nn.Conv2d(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         32\n",
    "        self.block3 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),)\n",
    "        self.end3 = nn.Conv2d(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         64\n",
    "        self.block4 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            nn.Conv2d(512, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),)\n",
    "        self.end4 = nn.Conv2d(256, 3, 1, 1, 0)\n",
    "        \n",
    "#          128\n",
    "        self.block5 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),)\n",
    "        self.end5 = nn.Conv2d(128, 3, 1, 1, 0)\n",
    "\n",
    "\n",
    "#     Get this down to one if statement logic for fade in\n",
    "    def forward(self, input, res, alpha):\n",
    "        \n",
    "        \n",
    "        \n",
    "        if res == 4:\n",
    "            output = self.block(input)\n",
    "            output = self.end(output)\n",
    "        elif res == 8:\n",
    "            output = self.block(input)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end(output_old)\n",
    "            output = self.block1(output)\n",
    "            output = self.end1(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 16:\n",
    "            output = self.block(input)\n",
    "            output = self.block1(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end1(output_old)\n",
    "            output = self.block2(output)\n",
    "            output = self.end2(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 32:\n",
    "            output = self.block(input)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end2(output_old)\n",
    "            output = self.block3(output)\n",
    "            output = self.end3(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 64:\n",
    "            output = self.block(input)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end3(output_old)\n",
    "            output = self.block4(output)\n",
    "            output = self.end4(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 128:\n",
    "            output = self.block(input)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block4(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end4(output_old)\n",
    "            output = self.block5(output)\n",
    "            output = self.end5(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "#         print(output.shape) \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "#         self.added = nn.ModuleList([])\n",
    "        self.down_samp = nn.AvgPool2d(2)\n",
    "    \n",
    "#         4\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(512, 512, 4, 1, 0),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1))\n",
    "        self.start = nn.Conv2d(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         8\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start1 = nn.Conv2d(3, 512, 1, 1, 0)\n",
    "\n",
    "#         16\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start2 = nn.Conv2d(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         32\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start3 = nn.Conv2d(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         64\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start4 = nn.Conv2d(3, 256, 1, 1, 0)\n",
    "        \n",
    "#         128\n",
    "        self.block5= nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start5 = nn.Conv2d(3, 128, 1, 1, 0)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, input, res, alpha):   \n",
    "        \n",
    "        if res == 4:\n",
    "            output = self.start(input)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 8:\n",
    "            output = self.start1(input)\n",
    "            output = self.block1(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block(output)\n",
    "        \n",
    "        elif res == 16:\n",
    "            output = self.start2(input)\n",
    "            output = self.block2(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start1(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "                \n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 32:\n",
    "            output = self.start3(input)\n",
    "            output = self.block3(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start2(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 64:\n",
    "            output = self.start4(input)\n",
    "            output = self.block4(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start3(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "                \n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 128:\n",
    "            output = self.start5(input)\n",
    "            output = self.block5(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start4(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block4(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "#         print(output.shape) \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "# with torch.cuda.amp.autocast(): \n",
    "#     test = torch.randn(16, nz, 1, 1, device=device)\n",
    "#     test1 = torch.randn(16, 3, 128, 128, device=device)\n",
    "    \n",
    "#     temp = netG(test, res = 8, alpha = 1)\n",
    "#     print(temp.shape)\n",
    "#     netD(temp, res = 8, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "output_fake torch.Size([16])\n",
      "output_real torch.Size([16])\n",
      "grad_pen torch.Size([16])\n",
      "penalty torch.Size([16])\n",
      "Res: 4 Fade_in: False Iter: 16\n",
      "W with GP: -59.21198654174805 Loss G: 184.03488159179688\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss_real' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-d5dbfa40c565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-d5dbfa40c565>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Res:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fade_in:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfade_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Iter:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W with GP:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"Loss G:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss real:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Loss Fake:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_real' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def training():\n",
    "\n",
    "\n",
    "    # Create batch of latent vectors that we will use to visualize\n",
    "    #  the progression of the generator\n",
    "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "    # Establish convention for real and fake labels during training\n",
    "    real_label = 1.\n",
    "    fake_label = 0\n",
    "    \n",
    "    label = torch.tensor(1)\n",
    "\n",
    "    # Setup Adam optimizers for both G and D\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    scalerD = torch.cuda.amp.GradScaler()\n",
    "    scalerG = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    \n",
    "    training = True\n",
    "    current_data = 0\n",
    "    res = 4\n",
    "    fade_in = False\n",
    "    \n",
    "    while(training):\n",
    "        steps = 2000\n",
    "        loader = iter(data_loaders[current_data])\n",
    "        count = 0\n",
    "        \n",
    "    \n",
    "        while count < steps:\n",
    "            try:\n",
    "                img = loader.next()\n",
    "            except StopIteration:\n",
    "                loader = iter(data_loaders[current_data])\n",
    "                img = loader.next()\n",
    "            if fade_in:\n",
    "                alpha = -1\n",
    "               \n",
    "            else:\n",
    "                alpha = count/steps\n",
    "                \n",
    "            mini_batch = len(img[0])\n",
    "    \n",
    "            real_imgs = img[0].to(device)\n",
    "        \n",
    "            netD.zero_grad()\n",
    "            \n",
    "#             Discriminator loss on real images\n",
    "\n",
    "            output_real = netD(real_imgs, alpha=alpha, res=res).squeeze()\n",
    "\n",
    "            \n",
    "#             Discriminator loss on fake images\n",
    "            \n",
    "            noise = torch.randn(mini_batch, nz, 1, 1, device=device)\n",
    "            fake_imgs = netG(noise, res=res, alpha=alpha)\n",
    "            output_fake = netD(fake_imgs.detach(), alpha=alpha, res=res).squeeze()\n",
    "            \n",
    "\n",
    "#             Gradient Penalty\n",
    "            \n",
    "            gp_alpha = torch.randn(mini_batch, 1, 1, 1, device = device)\n",
    "            interp = gp_alpha * real_imgs + ((1-gp_alpha) * fake_imgs.detach())\n",
    "            interp.requires_grad = True\n",
    "            model_interp = netD(interp, alpha = alpha, res = res)\n",
    "            grads = torch.autograd.grad(outputs=model_interp, inputs=interp,\n",
    "                          grad_outputs=torch.ones(model_interp.size()).to(device),\n",
    "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "            grads = torch.square(grads)\n",
    "            grads = torch.sum(grads, dim = [1,2,3])\n",
    "            grads = torch.sqrt(grads)\n",
    "            grads = grads - 1\n",
    "            grads = torch.square(grads)\n",
    "            grad_pen = grads * lambda_gp\n",
    "            \n",
    "#             Extra small penalty\n",
    "\n",
    "            penalty = torch.square(output_real)\n",
    "            penalty = penalty * .001\n",
    "        \n",
    "#             Calculating entire loss and taking step\n",
    "            \n",
    "            loss_D = output_fake - output_real + grad_pen + penalty\n",
    "            loss_D = loss_D.mean()\n",
    "            \n",
    "            loss_D.backward()\n",
    "            \n",
    "            optimizerD.step()\n",
    "#             loss_D = loss_fake + loss_real + grad_pen\n",
    "            \n",
    "                \n",
    "                \n",
    "            netG.zero_grad()\n",
    "            \n",
    "#             Generator loss on created batch\n",
    "\n",
    "            output = netD(fake_imgs, alpha=alpha, res=res).squeeze()\n",
    "            loss_G = -torch.mean(output)\n",
    "            loss_G.backward()    \n",
    "\n",
    "            optimizerG.step()\n",
    "\n",
    "            \n",
    "\n",
    "                \n",
    "            count += mini_batch\n",
    "            if count %500 <= mini_batch:\n",
    "                print(\"Res:\", res, \"Fade_in:\", fade_in, \"Iter:\",count)\n",
    "                print(\"W with GP:\", loss_D.item(),  \"Loss G:\", loss_G.item())\n",
    "#                 print(\"Loss real:\", loss_real.item(), \"Loss Fake:\", loss_fake.item())\n",
    "                print()\n",
    "        \n",
    "        \n",
    "        if fade_in == False:\n",
    "            fade_in = True\n",
    "            current_data += 1\n",
    "            res = res * 2\n",
    "        else:\n",
    "            fade_in = False\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "training()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 4, 4]) tensor(0.2948) tensor(0.5572)\n",
      "torch.Size([64, 4, 4, 3]) tensor(0.2948) tensor(0.5572)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# OldRange = (OldMax - OldMin)  \n",
    "# NewRange = (NewMax - NewMin)  \n",
    "# NewValue = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
    "\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "with torch.no_grad():\n",
    "    guess = netG(fixed_noise, res = 4, alpha=1)\n",
    "    guess = guess.cpu()\n",
    "    old_min = torch.min(guess)\n",
    "    old_max = torch.max(guess)\n",
    "    old_range = old_max - old_min\n",
    "    new_range = 1 - 0\n",
    "    guess = (((guess - old_min)*new_range)/ old_range) + 0\n",
    "#     guess = guess.float()\n",
    "    print(guess.shape, torch.min(guess[0]), torch.max(guess[0]))\n",
    "#     guess = ((guess *.5 ) + .5)\n",
    "    guess = guess.permute(0,2,3,1)\n",
    "    print(guess.shape, torch.min(guess[0]), torch.max(guess[0]))\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(guess[i, :, :])\n",
    "        plt.axis('off')\n",
    "#     plt.savefig('end_train.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get it working without mixed precision  \n",
    "\n",
    "\n",
    "\n",
    "# #             Discriminator loss on real images\n",
    "#             with torch.cuda.amp.autocast(): \n",
    "#                 output_real = netD(real_imgs, alpha=alpha, res=res).squeeze()\n",
    "#                 loss_real = -torch.mean(output_real)\n",
    "# #                 print(loss_real)\n",
    "# #             print(loss_real) \n",
    "#             scalerD.scale(loss_real).backward()\n",
    "# #             print(loss_real)\n",
    "\n",
    "            \n",
    "#             noise = torch.randn(mini_batch, nz, 1, 1, device=device)\n",
    "            \n",
    "# #             Discriminator loss on fake images\n",
    "#             with torch.cuda.amp.autocast():\n",
    "            \n",
    "#                 fake_imgs = netG(noise, res=res, alpha=alpha)\n",
    "#                 output_fake = netD(fake_imgs.detach(), alpha=alpha, res=res).squeeze()\n",
    "                \n",
    "#                 loss_fake = torch.mean(output_fake)\n",
    "            \n",
    "#             scalerD.scale(loss_fake).backward()\n",
    "            \n",
    "# #             Gradient Penalty\n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 gp_alpha = torch.randn(mini_batch, 1, 1, 1, device = device)\n",
    "#                 gp_alpha = gp_alpha.expand(real_imgs.size(0), real_imgs.size(1), real_imgs.size(2), real_imgs.size(3))\n",
    "#                 interp = gp_alpha * real_imgs + ((1-gp_alpha) * fake_imgs.detach())\n",
    "#                 interp.requires_grad = True\n",
    "#                 model_interp = netD(interp, alpha = alpha, res = res)\n",
    "            \n",
    "#             grads = torch.autograd.grad(outputs=model_interp, inputs=interp,\n",
    "#                               grad_outputs=torch.ones(model_interp.size()).to(device),\n",
    "#                               create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "            \n",
    "# #             Do I need to unscale the gradients for calculating gp for wasserstein?\n",
    "# #             print(scaled_grad_params.shape)\n",
    "# #             inv_scale = 1./scalerD.get_scale()\n",
    "# #             grads = [p * inv_scale for p in scaled_grad_params]\n",
    "# #             print(grads)\n",
    "            \n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 grads = ((grads.norm(2, dim=1) - 1) ** 2).mean()\n",
    "#                 grads += 1e-16\n",
    "#                 grad_pen = grads * lambda_gp\n",
    "# #                 print(grad_pen.item())\n",
    "            \n",
    "#             scalerD.scale(grad_pen).backward()\n",
    "# #             print(grad_pen.item())\n",
    "# #             return\n",
    "#             scalerD.step(optimizerD)\n",
    "#             scalerD.update()\n",
    "#             loss_D = loss_fake + loss_real + grad_pen\n",
    "            \n",
    "                \n",
    "                \n",
    "#             netG.zero_grad()\n",
    "            \n",
    "\n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 output = netD(fake_imgs, alpha=alpha, res=res).squeeze()\n",
    "#                 loss_G = -torch.mean(output)\n",
    "#             scalerG.scale(loss_G).backward()    \n",
    "\n",
    "#             scalerG.step(optimizerG)\n",
    "#             scalerG.update()\n",
    "                \n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
