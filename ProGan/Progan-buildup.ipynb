{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Root directory for dataset\n",
    "dataroot = \"/media/fico/Data/Celeba/CelebAMask-HQ\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "\n",
    "\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 512\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 4\n",
    "\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "lambda_gp = 10\n",
    "\n",
    "d_ratio = 1\n",
    "\n",
    "img_batch_size = [(4,16),(8,16),(16,16),(32,16)]#(64,16),(128,16)]\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.8980) tensor(0.8510)\n"
     ]
    }
   ],
   "source": [
    "data_loaders = []\n",
    "for img_size, batch_size in img_batch_size:\n",
    "    dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.CenterCrop(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "    dataload = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=workers, drop_last=True)\n",
    "    data_loaders.append(dataload)\n",
    "\n",
    "x = next(iter(data_loaders[0]))\n",
    "print(torch.min(x[0]), torch.max(x[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hukkelas/progan-pytorch/blob/master/src/models/custom_layers.py\n",
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        div = torch.square(x)\n",
    "        div = torch.mean(div, dim = 1, keepdim = True)\n",
    "        div = div + 10**(-8)\n",
    "        div = torch.square(div)\n",
    "        return x/div\n",
    "\n",
    "class MiniBatchSTD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiniBatchSTD, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        s = x.shape\n",
    "        std = x.to(torch.float32)   \n",
    "        std = std - torch.mean(std, dim=0, keepdim= True)\n",
    "        std = torch.mean(torch.square(std), dim=0)\n",
    "        std = torch.sqrt(std + 10**(-8))\n",
    "        std = torch.mean(std)\n",
    "        std = std.to(x.dtype)\n",
    "        std = std.repeat([s[0], 1, s[2], s[3]])\n",
    "        std = torch.cat([x, std], 1)\n",
    "#         print(std.shape)\n",
    "        return std\n",
    "# https://github.com/akanimax/pro_gan_pytorch/blob/master/pro_gan_pytorch/CustomLayers.py\n",
    "class conv2d_e(nn.Module):\n",
    "    def __init__(self, input_c, output_c, kernel, stride, pad):\n",
    "        super(conv2d_e, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.nn.init.normal_(torch.empty(output_c, input_c, kernel, kernel)))\n",
    "        self.bias = torch.nn.Parameter(torch.FloatTensor(output_c).fill_(0))\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        fan_in = (kernel*kernel) * input_c\n",
    "        self.scale = (2/fan_in)**.5\n",
    "#         print(self.weight.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.conv2d(input = x, \n",
    "                         weight = self.weight * self.scale, \n",
    "                         stride = self.stride, \n",
    "                         bias = self.bias, \n",
    "                         padding = self.pad)\n",
    "        \n",
    "        return std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Gen Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "# Use upsample from latent or use dense layer to upsample?\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "#         self.added = nn.ModuleList([])\n",
    "        self.up_samp = nn.Upsample(scale_factor = 2)\n",
    "#         4\n",
    "        self.start = nn.Linear(512, 8192)\n",
    "        self.block = nn.Sequential(\n",
    "#             nn.Upsample(scale_factor = 4),\n",
    "            conv2d_e(nz, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            PixelNorm(),)\n",
    "        self.end = nn.Conv2d(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         8\n",
    "        self.block1 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True), \n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True), \n",
    "            PixelNorm(),) \n",
    "        self.end1 = nn.Conv2d(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         16\n",
    "        self.block2 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            PixelNorm(),)\n",
    "        self.end2 = nn.Conv2d(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         32\n",
    "        self.block3 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            PixelNorm(),)\n",
    "        self.end3 = nn.Conv2d(512, 3, 1, 1, 0)\n",
    "        \n",
    "#         64\n",
    "        self.block4 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(512, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(256, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            PixelNorm(),)\n",
    "        self.end4 = nn.Conv2d(256, 3, 1, 1, 0)\n",
    "        \n",
    "#          128\n",
    "        self.block5 = nn.Sequential(\n",
    "            self.up_samp,\n",
    "            conv2d_e(256, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            PixelNorm(),\n",
    "            conv2d_e(128, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            PixelNorm(),)\n",
    "        self.end5 = nn.Conv2d(128, 3, 1, 1, 0)\n",
    "\n",
    "\n",
    "#     Get this down to one if statement logic for fade in\n",
    "    def forward(self, input, res, alpha):\n",
    "#         print(input.shape)\n",
    "#         intput1 = se\n",
    "        input1 = self.start(input)\n",
    "        input1 = input1.view(-1,512,4,4)\n",
    "\n",
    "        \n",
    "        if res == 4:\n",
    "            output = self.block(input1)\n",
    "            output = self.end(output)\n",
    "        elif res == 8:\n",
    "            output = self.block(input1)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end(output_old)\n",
    "            output = self.block1(output)\n",
    "            output = self.end1(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 16:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end1(output_old)\n",
    "            output = self.block2(output)\n",
    "            output = self.end2(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 32:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end2(output_old)\n",
    "            output = self.block3(output)\n",
    "            output = self.end3(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 64:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end3(output_old)\n",
    "            output = self.block4(output)\n",
    "            output = self.end4(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "        elif res == 128:\n",
    "            output = self.block(input1)\n",
    "            output = self.block1(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block4(output)\n",
    "            if alpha >= 0:\n",
    "                output_old = self.up_samp(output)\n",
    "                output_old = self.end4(output_old)\n",
    "            output = self.block5(output)\n",
    "            output = self.end5(output)\n",
    "            if alpha >= 0:\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "#         print(output.shape) \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dis Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Implement batchstdev\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "#         self.added = nn.ModuleList([])\n",
    "        self.down_samp = nn.AvgPool2d(2)\n",
    "    \n",
    "#         4\n",
    "        self.block = nn.Sequential(\n",
    "            MiniBatchSTD(),\n",
    "            conv2d_e(513, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            conv2d_e(512, 512, 4, 1, 0),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1))\n",
    "        self.start = nn.Conv2d(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         8\n",
    "        self.block1 = nn.Sequential(\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start1 = nn.Conv2d(3, 512, 1, 1, 0)\n",
    "\n",
    "#         16\n",
    "        self.block2 = nn.Sequential(\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start2 = nn.Conv2d(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         32\n",
    "        self.block3 = nn.Sequential(\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            conv2d_e(512, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start3 = nn.Conv2d(3, 512, 1, 1, 0)\n",
    "        \n",
    "#         64\n",
    "        self.block4 = nn.Sequential(\n",
    "            conv2d_e(256, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            conv2d_e(256, 512, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start4 = nn.Conv2d(3, 256, 1, 1, 0)\n",
    "        \n",
    "#         128\n",
    "        self.block5= nn.Sequential(\n",
    "            conv2d_e(128, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            conv2d_e(128, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(True),\n",
    "            self.down_samp,)\n",
    "        self.start5 = nn.Conv2d(3, 128, 1, 1, 0)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, input, res, alpha):   \n",
    "        \n",
    "        if res == 4:\n",
    "            output = self.start(input)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 8:\n",
    "            output = self.start1(input)\n",
    "            output = self.block1(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block(output)\n",
    "        \n",
    "        elif res == 16:\n",
    "            output = self.start2(input)\n",
    "            output = self.block2(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start1(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "                \n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 32:\n",
    "            output = self.start3(input)\n",
    "            output = self.block3(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start2(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 64:\n",
    "            output = self.start4(input)\n",
    "            output = self.block4(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start3(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "                \n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "        elif res == 128:\n",
    "            output = self.start5(input)\n",
    "            output = self.block5(output)\n",
    "            \n",
    "            if alpha >= 0:\n",
    "                output_old = self.down_samp(input)\n",
    "                output_old = self.start4(output_old)\n",
    "                output = alpha*output + (1-alpha)*output_old\n",
    "            \n",
    "            output = self.block4(output)\n",
    "            output = self.block3(output)\n",
    "            output = self.block2(output)\n",
    "            output = self.block1(output)\n",
    "            output = self.block(output)\n",
    "            \n",
    "#         print(output.shape) \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3479],\n",
       "        [-0.3477],\n",
       "        [-0.3481],\n",
       "        [-0.3479],\n",
       "        [-0.3478],\n",
       "        [-0.3481],\n",
       "        [-0.3477],\n",
       "        [-0.3479],\n",
       "        [-0.3483],\n",
       "        [-0.3477],\n",
       "        [-0.3481],\n",
       "        [-0.3483],\n",
       "        [-0.3480],\n",
       "        [-0.3482],\n",
       "        [-0.3481],\n",
       "        [-0.3481]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "netD = Discriminator(ngpu).to(device)\n",
    " \n",
    "test = torch.randn(16, nz, device=device)\n",
    "test1 = torch.randn(16, 3, 128, 128, device=device)\n",
    "\n",
    "temp = netG(test, res = 4, alpha = -1)\n",
    "# print(temp.shape)\n",
    "netD(temp, res = 4, alpha = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: 4 Fade_in: False Iter: 16\n",
      "W with GP: 1.232893705368042 Loss G: -0.23637914657592773\n",
      "\n",
      "Res: 4 Fade_in: False Iter: 512\n",
      "W with GP: -1.1111133098602295 Loss G: 0.09123528748750687\n",
      "\n",
      "Res: 8 Fade_in: True Iter: 16\n",
      "W with GP: 2.4709312915802 Loss G: -0.08017022162675858\n",
      "\n",
      "Res: 8 Fade_in: True Iter: 512\n",
      "W with GP: -4.523257255554199 Loss G: 1.044843077659607\n",
      "\n",
      "Res: 8 Fade_in: False Iter: 16\n",
      "W with GP: 0.3198676109313965 Loss G: 0.5441128015518188\n",
      "\n",
      "Res: 8 Fade_in: False Iter: 512\n",
      "W with GP: -3.0119476318359375 Loss G: 1.9160621166229248\n",
      "\n",
      "Res: 16 Fade_in: True Iter: 16\n",
      "W with GP: 4.814914226531982 Loss G: 45.74358367919922\n",
      "\n",
      "Res: 16 Fade_in: True Iter: 512\n",
      "W with GP: -7.569674968719482 Loss G: 6.821462631225586\n",
      "\n",
      "Res: 16 Fade_in: False Iter: 16\n",
      "W with GP: -2.0010428428649902 Loss G: 3.1378207206726074\n",
      "\n",
      "Res: 16 Fade_in: False Iter: 512\n",
      "W with GP: -8.079158782958984 Loss G: 9.242892265319824\n",
      "\n",
      "Res: 32 Fade_in: True Iter: 16\n",
      "W with GP: 2.1662790775299072 Loss G: 8.906649589538574\n",
      "\n",
      "Res: 32 Fade_in: True Iter: 512\n",
      "W with GP: nan Loss G: nan\n",
      "\n",
      "Res: 32 Fade_in: False Iter: 16\n",
      "W with GP: nan Loss G: nan\n",
      "\n",
      "Res: 32 Fade_in: False Iter: 512\n",
      "W with GP: nan Loss G: nan\n",
      "\n",
      "Res: 64 Fade_in: True Iter: 16\n",
      "W with GP: nan Loss G: nan\n",
      "\n",
      "Res: 64 Fade_in: True Iter: 512\n",
      "W with GP: nan Loss G: nan\n",
      "\n",
      "Res: 64 Fade_in: False Iter: 16\n",
      "W with GP: nan Loss G: nan\n",
      "\n",
      "Res: 64 Fade_in: False Iter: 512\n",
      "W with GP: nan Loss G: nan\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 7.79 GiB total capacity; 5.63 GiB already allocated; 107.56 MiB free; 6.34 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-341-a66c1eab987f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-341-a66c1eab987f>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mfake_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moutput_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-338-c979a0357422>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, res, alpha)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-333-a83dc235c01b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m                          \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                          \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                          padding = self.pad)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 7.79 GiB total capacity; 5.63 GiB already allocated; 107.56 MiB free; 6.34 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "\n",
    "def training():\n",
    "\n",
    "\n",
    "    # Setup Adam optimizers for both G and D\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    \n",
    "    \n",
    "    training = True\n",
    "    current_data = 0\n",
    "    res = 4\n",
    "    fade_in = False\n",
    "    \n",
    "    while(training):\n",
    "        steps = 550\n",
    "        loader = iter(data_loaders[current_data])\n",
    "        count = 0\n",
    "        \n",
    "    \n",
    "        while count < steps:\n",
    "            try:\n",
    "                img = loader.next()\n",
    "            except StopIteration:\n",
    "                loader = iter(data_loaders[current_data])\n",
    "                img = loader.next()\n",
    "            if fade_in:\n",
    "                alpha = -1\n",
    "               \n",
    "            else:\n",
    "                alpha = count/steps\n",
    "                \n",
    "            mini_batch = len(img[0])\n",
    "    \n",
    "            real_imgs = img[0].to(device)\n",
    "        \n",
    "            netD.zero_grad()\n",
    "            \n",
    "#             Discriminator loss on real images\n",
    "\n",
    "            output_real = netD(real_imgs, alpha=alpha, res=res).squeeze()\n",
    "\n",
    "            \n",
    "#             Discriminator loss on fake images\n",
    "            \n",
    "            noise = torch.randn(mini_batch, nz, device=device)\n",
    "            fake_imgs = netG(noise, res=res, alpha=alpha)\n",
    "            output_fake = netD(fake_imgs.detach(), alpha=alpha, res=res).squeeze()\n",
    "            \n",
    "\n",
    "#             Gradient Penalty\n",
    "            \n",
    "            gp_alpha = torch.randn(mini_batch, 1, 1, 1, device = device)\n",
    "            interp = gp_alpha * real_imgs + ((1-gp_alpha) * fake_imgs.detach())\n",
    "            interp.requires_grad = True\n",
    "            model_interp = netD(interp, alpha = alpha, res = res)\n",
    "            grads = torch.autograd.grad(outputs=model_interp, inputs=interp,\n",
    "                          grad_outputs=torch.ones(model_interp.size()).to(device),\n",
    "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "            grads = torch.square(grads)\n",
    "            grads = torch.sum(grads, dim = [1,2,3])\n",
    "            grads = torch.sqrt(grads)\n",
    "            grads = grads - 1\n",
    "            grads = torch.square(grads)\n",
    "            grad_pen = grads * lambda_gp\n",
    "            \n",
    "#             Extra small penalty\n",
    "\n",
    "            penalty = torch.square(output_real)\n",
    "            penalty = penalty * .001\n",
    "        \n",
    "#             Calculating entire loss and taking step\n",
    "            \n",
    "            loss_D = torch.mean(output_fake - output_real + grad_pen + penalty)\n",
    "            \n",
    "            \n",
    "            loss_D.backward()\n",
    "            \n",
    "            optimizerD.step()\n",
    "#             loss_D = loss_fake + loss_real + grad_pen\n",
    "            \n",
    "                \n",
    "                \n",
    "            netG.zero_grad()\n",
    "            \n",
    "#             Generator loss on created batch\n",
    "\n",
    "            output = netD(fake_imgs, alpha=alpha, res=res).squeeze()\n",
    "            loss_G = -torch.mean(output)\n",
    "            loss_G.backward()    \n",
    "\n",
    "            optimizerG.step()\n",
    "\n",
    "#             Training Stats\n",
    "                \n",
    "            count += mini_batch\n",
    "            if count %500 <= mini_batch:\n",
    "                print(\"Res:\", res, \"Fade_in:\", fade_in, \"Iter:\",count)\n",
    "                print(\"W with GP:\", loss_D.item(),  \"Loss G:\", loss_G.item())\n",
    "#                 print(\"Loss real:\", loss_real.item(), \"Loss Fake:\", loss_fake.item())\n",
    "                print()\n",
    "        \n",
    "        \n",
    "        if fade_in == False:\n",
    "            fade_in = True\n",
    "            current_data += 1\n",
    "            if current_data == len(data_loaders):\n",
    "                training= False\n",
    "            res = res * 2\n",
    "        else:\n",
    "            fade_in = False\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "training()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 4, 4]) tensor(0.) tensor(1.)\n",
      "torch.Size([256, 4, 4, 3]) tensor(0.4994) tensor(0.5426)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# OldRange = (OldMax - OldMin)  \n",
    "# NewRange = (NewMax - NewMin)  \n",
    "# NewValue = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
    "\n",
    "\n",
    "fixed_noise = torch.randn(256, nz, device=device)\n",
    "with torch.no_grad():\n",
    "    guess = netG(fixed_noise, res = 4, alpha=-1)\n",
    "    guess = guess.cpu()\n",
    "#     guess = next(iter(data_loaders[0]))[0]\n",
    "#     print(guess[0].shape)\n",
    "    old_min = torch.min(guess)\n",
    "    old_max = torch.max(guess)\n",
    "    old_range = old_max - old_min\n",
    "    new_range = 1 - 0\n",
    "    guess = (((guess - old_min)*new_range)/ old_range) + 0\n",
    "#     guess = guess.float()\n",
    "    print(guess.shape, torch.min(guess), torch.max(guess))\n",
    "#     guess = ((guess *.5 ) + .5)\n",
    "    guess = guess.permute(0,2,3,1)\n",
    "    print(guess.shape, torch.min(guess[0]), torch.max(guess[0]))\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(guess[i, :, :])\n",
    "        plt.axis('off')\n",
    "#     plt.savefig('end_train.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get it working without mixed precision  \n",
    "\n",
    "\n",
    "\n",
    "# #             Discriminator loss on real images\n",
    "#             with torch.cuda.amp.autocast(): \n",
    "#                 output_real = netD(real_imgs, alpha=alpha, res=res).squeeze()\n",
    "#                 loss_real = -torch.mean(output_real)\n",
    "# #                 print(loss_real)\n",
    "# #             print(loss_real) \n",
    "#             scalerD.scale(loss_real).backward()\n",
    "# #             print(loss_real)\n",
    "\n",
    "            \n",
    "#             noise = torch.randn(mini_batch, nz, 1, 1, device=device)\n",
    "            \n",
    "# #             Discriminator loss on fake images\n",
    "#             with torch.cuda.amp.autocast():\n",
    "            \n",
    "#                 fake_imgs = netG(noise, res=res, alpha=alpha)\n",
    "#                 output_fake = netD(fake_imgs.detach(), alpha=alpha, res=res).squeeze()\n",
    "                \n",
    "#                 loss_fake = torch.mean(output_fake)\n",
    "            \n",
    "#             scalerD.scale(loss_fake).backward()\n",
    "            \n",
    "# #             Gradient Penalty\n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 gp_alpha = torch.randn(mini_batch, 1, 1, 1, device = device)\n",
    "#                 gp_alpha = gp_alpha.expand(real_imgs.size(0), real_imgs.size(1), real_imgs.size(2), real_imgs.size(3))\n",
    "#                 interp = gp_alpha * real_imgs + ((1-gp_alpha) * fake_imgs.detach())\n",
    "#                 interp.requires_grad = True\n",
    "#                 model_interp = netD(interp, alpha = alpha, res = res)\n",
    "            \n",
    "#             grads = torch.autograd.grad(outputs=model_interp, inputs=interp,\n",
    "#                               grad_outputs=torch.ones(model_interp.size()).to(device),\n",
    "#                               create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "            \n",
    "# #             Do I need to unscale the gradients for calculating gp for wasserstein?\n",
    "# #             print(scaled_grad_params.shape)\n",
    "# #             inv_scale = 1./scalerD.get_scale()\n",
    "# #             grads = [p * inv_scale for p in scaled_grad_params]\n",
    "# #             print(grads)\n",
    "            \n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 grads = ((grads.norm(2, dim=1) - 1) ** 2).mean()\n",
    "#                 grads += 1e-16\n",
    "#                 grad_pen = grads * lambda_gp\n",
    "# #                 print(grad_pen.item())\n",
    "            \n",
    "#             scalerD.scale(grad_pen).backward()\n",
    "# #             print(grad_pen.item())\n",
    "# #             return\n",
    "#             scalerD.step(optimizerD)\n",
    "#             scalerD.update()\n",
    "#             loss_D = loss_fake + loss_real + grad_pen\n",
    "            \n",
    "                \n",
    "                \n",
    "#             netG.zero_grad()\n",
    "            \n",
    "\n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 output = netD(fake_imgs, alpha=alpha, res=res).squeeze()\n",
    "#                 loss_G = -torch.mean(output)\n",
    "#             scalerG.scale(loss_G).backward()    \n",
    "\n",
    "#             scalerG.step(optimizerG)\n",
    "#             scalerG.update()\n",
    "                \n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
