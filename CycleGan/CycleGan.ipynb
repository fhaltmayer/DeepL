{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "#     data_loaders = []\n",
    "#     for img_size, batch_size in img_batch_size:\n",
    "#         dataset = dset.ImageFolder(root=dataroot,\n",
    "#                            transform=transforms.Compose([\n",
    "#                                transforms.Resize(img_size),\n",
    "#                                transforms.CenterCrop(img_size),\n",
    "#                                transforms.ToTensor(),\n",
    "#                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#                            ]))\n",
    "\n",
    "#         dataload = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "#                                         shuffle=True, num_workers=workers, drop_last=True)\n",
    "#         data_loaders.append(dataload)\n",
    "#     # print(\"Data Loaded\")\n",
    "#     return data_loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "lamb = 10\n",
    "lr = .0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many different views on which design is best, using original resnet design\n",
    "class Residual2d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Residual2d, self).__init__()\n",
    "        self.res = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, 3, 1, 0),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, 3, 1, 0),\n",
    "            nn.InstanceNorm2d(dim))\n",
    "        self.relu = nn.ReLU(True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = x + self.res(x)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "# Use mirrored padding always or just beginning and final layer\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "#         3x256x256 -> 64x256x256\n",
    "        self.c7s1_64 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(3, 64, 7, 1, 0),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(True))\n",
    "    \n",
    "#         64x256x256 -> 128x128x128\n",
    "        self.d128 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(64, 128, 3, 2, 0),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(True))\n",
    "        \n",
    "#         128x128x128 -> 256x64x64\n",
    "        self.d256 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(128, 256, 3, 2, 0),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(True))\n",
    "        \n",
    "#         256x64x64 -> 256x64x64\n",
    "        res_blocks = [Residual2d(256) for x in range(9)]\n",
    "        self.R9 = nn.Sequential(*res_blocks)\n",
    "        \n",
    "#         Try using upsample + conv\n",
    "#         For some reason padding beforehand doesnt work with convtranpose, \n",
    "#         should work even with tranpose special padding rule\n",
    "#         256x64x64 -> 128x128x128\n",
    "        self.u128 = nn.Sequential(\n",
    "#             nn.ReflectionPad2d(1),\n",
    "            nn.ConvTranspose2d(256, 128, 3, 2, 1, output_padding=1),\n",
    "#             nn.ReflectionPad2d(1)\n",
    "        )\n",
    "        \n",
    "#         128x128x128 -> 64x256x256\n",
    "        self.u256 = nn.Sequential(\n",
    "#             nn.ReflectionPad2d(1),\n",
    "            nn.ConvTranspose2d(128, 64, 3, 2, 1, output_padding=1),\n",
    "#             nn.ReflectionPad2d(1)\n",
    "        )\n",
    "        \n",
    "        self.c7s1_3 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, 3, 7, 1, 0),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(True))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.c7s1_64(input)\n",
    "        output = self.d128(output)\n",
    "        output = self.d256(output)\n",
    "        output= self.R9(output)\n",
    "        output= self.u128(output)\n",
    "        output= self.u256(output)\n",
    "        output= self.c7s1_3(output)\n",
    "#         print(output.shape)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1611.07004.pdf\n",
    "# Try different patch sizes\n",
    "# Last two convolutions need to have a stride and padding of 1\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.C64 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace= True))\n",
    "    \n",
    "        self.C128 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace= True))\n",
    "        \n",
    "        self.C256 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace= True))\n",
    "    \n",
    "        self.C512 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 4, 1, 1),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace= True))\n",
    "        self.last = nn.Conv2d(512,1, 4, 1, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.C64(input)\n",
    "        output = self.C128(output)\n",
    "        output = self.C256(output)\n",
    "        output = self.C512(output)\n",
    "        output = self.last(output)\n",
    "\n",
    "\n",
    "\n",
    "#         print(output.shape)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: input\n",
    "# y: target\n",
    "# G: x -> y\n",
    "# F: y -> x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gx = gen_G(x)\n",
    "# Gy = gen_G(y)\n",
    "# FGx = gen_F(Gx)\n",
    "\n",
    "# Fy = gen_F(y)\n",
    "# Fx = gen_F(x)\n",
    "# GFy = gen_G(Fy)\n",
    "\n",
    "# # res_x = dis_x_vs_Fy(x)\n",
    "# res_Fy = dis_x_vs_Fy(Fy)\n",
    "# # res_y = dis_y_vs_Gx(y)\n",
    "# res_Gx = dis_y_vs_Gx(Gx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement buffering images later\n",
    "# class ImageBuffer\n",
    "#     def __init__(self):\n",
    "#         self.buffer = []\n",
    "#         self.buffer_size = 0\n",
    "#         self.last_image = -1\n",
    "    \n",
    "#     def add_image(image):\n",
    "#         if self.buffer_size < 50:\n",
    "#             self.buffer.append(image)\n",
    "#             self.last_image = self.buffer_size\n",
    "#             self.buffer_size += 1\n",
    "#         else:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGan:\n",
    "    def __init__(self):\n",
    "        self.gen_G = Generator().to(device)\n",
    "        self.gen_F = Generator().to(device)\n",
    "        self.dis_x_vs_Fy = Discriminator().to(device)\n",
    "        self.dis_y_vs_Gx = Discriminator().to(device)\n",
    "        self.Gx = -1\n",
    "        self.Fy = -1\n",
    "        self.lossGx = -1\n",
    "        self.lossFy= -1\n",
    "        self.lossY = -1\n",
    "        self.lossX = -1\n",
    "        self.crit = nn.MSELoss()\n",
    "        self.optimizer_gen_G = torch.optim.Adam(self.gen_G.parameters(), lr = lr)\n",
    "        self.optimizer_gen_F = torch.optim.Adam(self.gen_F.parameters(), lr = lr)\n",
    "        self.optimizer_dis_x = torch.optim.Adam(self.dis_x_vs_Fy.parameters(), lr = lr)\n",
    "        self.optimizer_dis_y = torch.optim.Adam(self.dis_y_vs_Gx.parameters(), lr = lr)\n",
    "    \n",
    "    def grad_toggle(self, grad):\n",
    "        for param in self.dis_x_vs_Fy.parameters():\n",
    "            param.requires_grad = grad\n",
    "        for param in self.dis_y_vs_Gx.parameters():\n",
    "            param.requires_grad = grad\n",
    "            \n",
    "    def loss_gen(self, result):\n",
    "        return self.crit(result, torch.zeros_like(result))\n",
    "    \n",
    "#     divide by 2 to slow down\n",
    "    def loss_dis(self, real, fake):\n",
    "        loss1 = self.crit(real, torch.ones_like(real))\n",
    "        loss2 = self.crit(fake, torch.zeros_like(fake))\n",
    "        return torch.mean((loss1 + loss2) * .5)\n",
    "\n",
    "    def loss_cyclic(self, real, cycled):\n",
    "        loss = torch.abs(cycled - real)\n",
    "        return torch.mean(loss) * lamb\n",
    "\n",
    "    # Found in 5.2 of paper, .5 found in git\n",
    "    def loss_identity(self, real, ident):\n",
    "        loss = torch.abs(ident - real)\n",
    "        return torch.mean(loss) * lamb * .5\n",
    "    \n",
    "    def generator_loss(self, x, y):\n",
    "        self.Gx = self.gen_G(x)\n",
    "        Gy = self.gen_G(y)\n",
    "        FGx = self.gen_F(self.Gx)\n",
    "\n",
    "        self.Fy = self.gen_F(y)\n",
    "        Fx = self.gen_F(x)\n",
    "        GFy = self.gen_G(self.Fy)\n",
    "        \n",
    "        self.grad_toggle(False)\n",
    "        \n",
    "        lossGx = self.loss_gen(self.dis_y_vs_Gx(self.Gx))\n",
    "        self.lossGx = lossGx.item()\n",
    "        \n",
    "        lossFy = self.loss_gen(self.dis_x_vs_Fy(self.Fy))\n",
    "        self.lossFy = lossFy.item()\n",
    "        \n",
    "        lossFGx = self.loss_cyclic(x, FGx)\n",
    "        lossGFy = self.loss_cyclic(y, GFy)\n",
    "        \n",
    "        identGy = self.loss_identity(y, Gy)\n",
    "        identFx = self.loss_identity(x, Fx)\n",
    "        \n",
    "        loss = lossGx + lossFy + lossFGx + lossGFy + identGy + identFx\n",
    "        \n",
    "        self.grad_toggle(True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def discriminator_loss(self, x, y):\n",
    "        dis_Gx = self.dis_y_vs_Gx(self.Gx.detach())\n",
    "        dis_y = self.dis_y_vs_Gx(y)\n",
    "        \n",
    "        dis_Fy = self.dis_x_vs_Fy(self.Fy.detach())\n",
    "        dis_x = self.dis_x_vs_Fy(x)\n",
    "        \n",
    "        loss_y = self.loss_dis(dis_y, dis_Gx)\n",
    "        self.lossY = loss_y.item()\n",
    "        \n",
    "        loss_x = self.loss_dis(dis_x, dis_Fy)\n",
    "        self.lossX = loss_x.item()\n",
    "        \n",
    "        loss = loss_x + loss_y\n",
    "        return loss\n",
    "        \n",
    "        \n",
    "    def step(self, x, y):\n",
    "        self.optimizer_gen_G.zero_grad()\n",
    "        self.optimizer_gen_F.zero_grad()\n",
    "        loss_g = self.generator_loss(x,y)\n",
    "        loss_g.backward()\n",
    "        self.optimizer_gen_G.step()\n",
    "        self.optimizer_gen_F.step()\n",
    "       \n",
    "        self.optimizer_dis_x.zero_grad()\n",
    "        self.optimizer_dis_y.zero_grad()\n",
    "        loss_d = self.discriminator_loss(x, y)\n",
    "        loss_d.backward()\n",
    "        self.optimizer_dis_x.step()\n",
    "        self.optimizer_dis_y.step()\n",
    "        print(\"loss Gx: \", self.lossGx, \"loss Fy: \", self.lossFy, \"loss disY: \", self.lossY, \"loss disX: \", self.lossX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,3,400,400).to(device)\n",
    "y = torch.rand(1,3,400,400).to(device)\n",
    "gan = CycleGan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss Gx:  0.19479721784591675 loss Fy:  0.1534479707479477 loss disY:  0.9343559741973877 loss disX:  0.5426048040390015\n"
     ]
    }
   ],
   "source": [
    "gan.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes to self\n",
    "# Load data as cropped not scaled images, then generate on full image, \n",
    "# Do data loading\n",
    "# Do checkpointing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
